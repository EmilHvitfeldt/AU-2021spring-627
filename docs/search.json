{
  "articles": [
    {
      "path": "01-labs.html",
      "title": "Lab 01 - Hello R!",
      "author": [],
      "contents": "\nLearning goals\nGet acquainted with R and RStudio, which we will be using throughout the course to analyze data as well as to learn the statistical concepts discussed in the course.\nAppreciate the value of visualization in exploring the relationship between variables.\nStart using R for building plots and calculating summary statistics.\nTerminology\nWe’ve already thrown around a few new terms, so let’s define them before we proceed.\nR: Name of the programming language we will be using throughout the course.\nRStudio: An integrated development environment for R. In other words, a convenient interface for writing and running R code.\nI like to think of R as the engine of the car, and RStudio is the dashboard.\nStarting slow\nAs the labs progress, you are encouraged to explore beyond what the labs dictate; a willingness to experiment will make you a much better programmer. Before we get to that stage, however, you need to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.\nAnd to make versioning simpler, this is a solo lab. Additionally, we want to make sure everyone gets a significant amount of time at the steering wheel.\nGetting started\nDownload R\nIf you don’t have R installed.\nGo to the CRAN and download R, make sure you get the version that matches your operating system.\nIf you have R installed\nIf you have R installed run the following code\n\n\nR.version\n\n\n               _                           \nplatform       x86_64-apple-darwin17.0     \narch           x86_64                      \nos             darwin17.0                  \nsystem         x86_64, darwin17.0          \nstatus                                     \nmajor          4                           \nminor          0.2                         \nyear           2020                        \nmonth          06                          \nday            22                          \nsvn rev        78730                       \nlanguage       R                           \nversion.string R version 4.0.2 (2020-06-22)\nnickname       Taking Off Again            \n\nThis should tell you what version of R you are currently using. If your R version is lower then 3.6.0 I would strongly recommend updating. In general it is a good idea to update your R version, unless you have a project right now that depend on a specific version of R.\nDownload RStudio\nWe recommend using RStudio as your IDE if you don’t already have it installed. You can go to the RStudio website to download and install the software.\nLaunch RStudio\nYou can also open the RStudio application first and then create a project by going file -> new project...\nCreate a new Rmarkdown file\nfile -> new file -> R markdown...\nHello RStudio!\nRStudio is comprised of four panes.\nOn the bottom left is the Console, this is where you can write code that will be evaluated. Try typing 2 + 2 here and hit enter, what do you get?\nOn the bottom right is the Files pane, as well as other panes that will come handy as we start our analysis.\nIf you click on a file, it will open in the editor, on the top left pane.\nFinally, the top right pane shows your Environment. If you define a variable it would show up there. Try typing x <- 2 in the Console and hit enter, what do you get in the Environment pane?\nPackages\nR is an open-source language, and developers contribute functionality to R via packages. In this lab we will work with three packages: palmerpenguins which contains the dataset, and tidyverse which is a collection of packages for doing data analysis in a “tidy” way.\nLoad these packages by running the following in the Console.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\n\n\nIf you haven’t installed these packages yet and R complains, then you can install these packages by running the following command. (Note that R package names are case-sensitive)\n\n\ninstall.packages(c(\"tidyverse\", \"palmerpenguins\"))\n\n\n\nNote that the packages are also loaded with the same commands in your R Markdown document.\nWarm up\nBefore we introduce the data, let’s warm up with some simple exercises.\nThe top portion of your R Markdown file (between the three dashed lines) is called YAML. It stands for “YAML Ain’t Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\nYAML\nOpen the R Markdown (Rmd) file in your project, change the author name to your name, and knit the document.\nData\nThe data frame we will be working with today is called penguins and it’s in the palmerpenguins package.\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(palmerpenguins)\n\npenguins\n\n\n\ncount the number of species and islands with dplyr::count()\nVisualize the distribution of body_mass_g with ggplot\n\n\nggplot(penguins, aes(body_mass_g)) +\n  geom_histogram()\n\n\n\nLook at the correlation between body_mass_g and some of the other variables\n\nggplot(penguins, aes(body_mass_g, ___)) +\n  geom_point()\n\nModeling\nFit a linear model using parsnip to model body_mass_g\n\nlm_spec <- linear_reg() %>%\n  set_engine(\"lm\")\n\nlm_fit <- lm_spec %>%\n  fit(___ ~ species + island + bill_length_mm + bill_depth_mm + flipper_length_mm, \n      data = penguins)\n\nlm_fit\n\nGet parameter estimates:\n\n\ntidy(lm_fit)\n\n\n\nFigures\nYou’re done with the data analysis exercises, but we’d like you to do two more things:\n\nResize your figures:\nClick on the gear icon in on top of the R Markdown document, and select “Output Options…” in the dropdown menu. In the pop up dialogue box go to the Figures tab and change the height and width of the figures, and hit OK when done. Then, knit your document and see how you like the new sizes. Change and knit again and again until you’re happy with the figure sizes. Note that these values get saved in the YAML.\n\nYou can also use different figure sizes for different figures. To do so click on the gear icon within the chunk where you want to make a change. Changing the figure sizes added new options to these chunks: fig.width and fig.height. You can change them by defining different values directly in your R Markdown document as well.\n\nChange the look of your report:\nOnce again click on the gear icon in on top of the R Markdown document, and select “Output Options…” in the dropdown menu. In the General tab of the pop up dialogue box try out different syntax highlighting and theme options. Hit OK and knit your document to see how it looks. Play around with these until you’re happy with the look.\nOptional\nIf you have time you can explore the different ways you can add styling to your rmarkdown document.\nHere is a cheatsheet\nand a markdown cheatsheet\nThis set of lab exersixes have been adopted from Mine Çetinkaya-Rundel’s class Introduction to Data Science.\n\n\n\n",
      "last_modified": "2021-01-25T18:01:52-08:00"
    },
    {
      "path": "01-readings.html",
      "title": "Readings - week 1",
      "author": [],
      "contents": "\nRead chapter 2 of “An Introduction to Statistical Learning”. This is a big picture chapter that lays the foundation of the rest of the book. It is not expected to have read this before class.\nChapter 1 serves as an introduction to the book, data, and notation. Can be read or skimmed through if you want.\nWe will be using R which can be downloaded here. Additionally, it is also advised to use RStudio which can be downloaded here, but any IDE will work.\nWe will be using the tidymodels ecosystem of packages designed for modeling. If you haven’t already you should install these packages along with tidyverse.\n\n\n\nSlides\n\n\n\nfitvids('.shareagain', {players: 'iframe'});\n\nPDF download\n\n\n\n",
      "last_modified": "2021-01-25T18:01:53-08:00"
    },
    {
      "path": "assignments-01.html",
      "title": "Assignment 1",
      "author": [],
      "contents": "\nExercise 1 (7 points)\nFor each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.\nThe sample size \\(n\\) is extremely large, and the number of predictors \\(p\\) is small.\nThe number of predictors \\(p\\) is extremely large, and the number of observations \\(n\\) is small.\nThe relationship between the predictors and response is highly non-linear.\nThe variance of the error terms, is extremely high.\nExercise 2 (6 points)\nDescribe the difference between a parametric and non-parametric statistical learning approach. What are the advantages of a parametric approach to regression or classification (as opposed to a noon-parametric approach)? What are its disadvantages?\nExercise 3 (6 points)\nCarefully explain the the difference between the KNN classifier and KNN regression methods. Name a downside when using this model on very large data.\nExercise 4 (7 points)\nSuppose we have a data set with five predictors, \\(X1 =\\) GPA, \\(X2 =\\) extracurricular activities (EA), \\(X3 =\\) Gender (1 for Female and 0 for Male), \\(X4 =\\) Interaction between GPA and EA, and \\(X5 =\\) Interaction between GPA and Gender. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get \\(\\beta_0 = 50\\), \\(\\beta_1 = 20\\), \\(\\beta_2 = 0.07\\), \\(\\beta_3 = 35\\), \\(\\beta_4 = 0.01\\), \\(\\beta_5 = - 10\\).\nWhich answer is correct, and why?\nFor a fixed value of EA and GPA, males earn more on average than females.\nFor a fixed value of EA and GPA, females earn more on average than males.\nFor a fixed value of EA and GPA, males earn more on average than females provided that the GPA is high enough.\nFor a fixed value of EA and GPA, females earn more on average than males provided that the GPA is high enough.\n\nPredict the salary of a female with EA of 110 and a GPA of 4.0.\nTrue or false: Since the coefficient for the GPA/EA interaction term is very small, there is very little evidence of an interaction effect. Justify your answer.\nExercise 5 (9 points)\nThis question should be answered using the biomass data set.\n\n\nlibrary(tidymodels)\ndata(\"biomass\")\n\n\n\nFit a multiple regression model to predict HHV using carbon, hydrogen and oxygen.\nProvide an interpretation of each coefficient in the model. Be careful, note the values Cruise is able to take.\nWrite out the model in equation form.\nFor which the predictors can you reject the null hypothesis \\(H_0: \\beta_j = 0\\)?\nOn the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.\nHow well do the models in (a) and (e) fit the data? How big was the effect of removing the predictor?\n\n\n\n",
      "last_modified": "2021-01-25T18:01:54-08:00"
    },
    {
      "path": "assignments.html",
      "title": "Assignments",
      "author": [],
      "contents": "\nWe will 10 weekly assignments, 1 midterm, and a final project in this class. The placement of these is located in the schedule.\nAssignments are to be turned in on Blackboard. Assignments will be available no later than 3 days before class and are due to be turned in on the following Sunday. Specific times can be found on Blackboard. The assignment will contain a mix of conceptual, technical, and coding exercises.\nThe midterm and final project will follow a different schedule specified on Blackboard.\n\n\n\n",
      "last_modified": "2021-01-25T18:01:54-08:00"
    },
    {
      "path": "index.html",
      "title": "Statistical Machine Learning",
      "description": "American University 427/627\n",
      "author": [],
      "contents": "\nThis website contains most of the information and material that will be used for one of the sections of the course Statistical Machine Learning at American University.\nThe navigation bar contains information about the syllabus, schedule, readings, labs and assignments.\nLicense\nThis online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International. Visit here for more information about the license.\nColophon\nThis book was written in RStudio using distill. The complete source is available on GitHub. All packages versions are being handled with renv.\n\n\n\n",
      "last_modified": "2021-01-25T18:01:55-08:00"
    },
    {
      "path": "labs-02.html",
      "title": "Labs - Week 2",
      "author": [],
      "contents": "\nThese sets of labs will introduce you to linear models. Both simple and multiple. This will also be your first introduction to the parsnip package which we will use to specify models.\nExercise 1 - Simple linear regression\nLoad the data biomass and plot HHV as a function of carbon.\n\n\nlibrary(tidymodels)\ndata(\"biomass\")\n\n\n\nFit a simple linear regression model to the data. With HHV as the response and carbon as the predictor. Is it a good fit?\nUse the model to predict what the HHV of samples with carbon = 10, 20, ..., 80.\nPlot the fitted line of the linear model.\nProduce diagnostics plots. You can use plot() on the $fit object to produce some diagnostics.\nExercise 2 - Multiple linear regression\nFit a linear regression model to the data. With HHV as the response and carbon and hydrogen as the predictor. How is the fit compared to the simple linear model?\nFit a linear regression model to the data. With HHV as the response and all the molecules as the predictor. How is the fit compared to the previous models?\n\n\n\n",
      "last_modified": "2021-01-25T18:01:56-08:00"
    },
    {
      "path": "labs.html",
      "title": "Labs",
      "author": [],
      "contents": "\nEach lecture will be followed by lab time which is sometimes where we will be using R and tidymodels to implement the methods we will have talked about that week.\nLabs are to be turned in on Blackboard. Albs will be available no later than 3 days before class and are due to be turned in on the following Sunday. We will be collectively be talking about the labs and come up with some of the answers. To get full credit for labs the document that is turned in should contain not just the right code to solve the problem but also text explaining what has been done.\n\n\n\n",
      "last_modified": "2021-01-25T18:01:56-08:00"
    },
    {
      "path": "readings-02.html",
      "title": "Readings - week 2",
      "author": [],
      "contents": "\nRead chapter 3 of “An Introduction to Statistical Learning”. This chapter goes over simple linear regression, multiple linear regression, and the considerations used in linear regression. As far as I can tell, you have all taken courses where linear regression has been introduced. It is still worthwhile for you to read this chapter to get familiar with the book, and hopefully, it will be an easy read.\nIf you want more information on the theoretical background you can read sections 3.1 and 3.2 of “The Elements of Statistical Learning”. This is optional reading.\nSlides\n\n\n\nfitvids('.shareagain', {players: 'iframe'});\n\nPDF download\n\n\n\n",
      "last_modified": "2021-01-25T18:01:57-08:00"
    },
    {
      "path": "readings.html",
      "title": "Readings",
      "author": [],
      "contents": "\nThe readings for this course will be based on the textbooks listed in the syllabus. Readings will primarily be taken from the main textbook, but will sometimes be other material. Additional optional reading will also be listed for each week for the students who want to dig deeper into the content of the week. Information from the optional reading will not be expected knowledge in the homework and the exams and should be seen as a learning opportunity only.\nReadings will be listed no later than 3 days before class. Reading before class is strongly encouraged to allow you to find the areas you have additional questions about and ask them in class.\nSlides will also be posted here for each week.\n\n\n\n",
      "last_modified": "2021-01-25T18:01:57-08:00"
    },
    {
      "path": "reference.html",
      "title": "Reference",
      "author": [],
      "contents": "\nVarious information links will be posted here as needed.\n\n\n\n",
      "last_modified": "2021-01-25T18:01:58-08:00"
    },
    {
      "path": "schedule.html",
      "title": "Schedule",
      "author": [],
      "contents": "\n\nContents\nWeek 1\nWeek 2\nWeek 3\nWeek 4\nWeek 5\nWeek 6\nWeek 7\nWeek 8\nWeek 9\nWeek 10\nWeek 11\nWeek 12\nWeek 13\nWeek 14\n\n\n\n\n\n\n\nWeek 1\n2021-01-17 to 2021-01-23\nTopics: Introductions, What is Statistical Machine Learning?, R, RStudio, Tidymodels\nreadings\nlabs\nNo Assignment this week\nWeek 2\n2021-01-24 to 2021-01-30\nTopics: Linear Regression, Regression\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 3\n2021-01-31 to 2021-02-06\nTopics: Logistic Regression, Classification, Train-Test Split\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 4\n2021-02-07 to 2021-02-13\nTopics: LDA, QDA, K-Nearest Neighbors\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 5\n2021-02-14 to 2021-02-20\nTopics: Bootstrap, Model Diagnostics, Evaluation Metrics\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 6\n2021-02-21 to 2021-02-27\nTopics: Cross Validation\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 7\n2021-02-28 to 2021-03-06\nTopics: Clustering, K-Means Clustering, Hierarchical Clustering\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nMidterm\nWeek 8\n2021-03-07 to 2021-03-13\nWellness Week\nTopics: Feature Engineering, Data Preprocessing\nNo readings, labs or assignment due to Wellness Week\nWeek 9\n2021-03-14 to 2021-03-20\nTopics: PCA, PCA Regression\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 10\n2021-03-21 to 2021-03-27\nTopics: Shrinkage Methods, Rigde, Lasso, Hyper Parameter Tuning\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 11\n2021-03-28 to 2021-04-03\nTopics: Splines, GAM\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 12\n2021-04-04 to 2021-04-10\nTopics: Decision Trees, Bagging, Boosting, Random Forrests\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 13\n2021-04-11 to 2021-04-17\nTopics: SVM\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nAssignments haven’t been posted yet\nWeek 14\n2021-04-18 to 2021-04-24\nTopics: Final Project\nReadings haven’t been posted yet\nLabs haven’t been posted yet\nNo assignment this week. Time will be dedicated for Final Project\n\n\n\n",
      "last_modified": "2021-01-25T18:02:00-08:00"
    },
    {
      "path": "syllabus.html",
      "title": "Syllabus",
      "author": [],
      "contents": "\n\nContents\nInstructor\nPre-requisites\nTextbooks\nMain textbook\nSupplementary books\nArticles, book chapters, and other materials\n\nCourse Plan\nAssignments and grading\nLearning objectives\nOnline help\nSoftware\nLearning during a pandemic\nLauren’s Promise\nSupport Services\nEmergency preparedness\nMathematics & Statistics Tutoring Lab (Don Myers Building)\nAcademic Support and Access Center\nCenter for Diversity & Inclusion (X3651, MGC 201)\nThe Office of Advocacy Services for Interpersonal and Sexual Violence (X7070)\nCounseling Center (x3500)\nReligious Holidays\nAcademic Integrity Code\n\n\nInstructor\nInstructor: Emil Hvitfeldt\nTime: Tuesday 5:30PM - 8:00PM ET time zone (Washington DC time)\nCourse website: https://emilhvitfeldt.github.io/AU-2021spring-627/index.html\nOffice hours: Sunday 6:00PM - 7:00PM\nEmail: emilh@american.edu\nTwiter: @Emil_Hvitfeldt\nE-mail and Slack are the best ways to get in contact with me. I will try to respond to all course-related e-mails and Slack messages within 24 hours (really) but also remember that life can be busy and chaotic for everyone (including me!), so if I don’t respond right away, don’t worry!\nPre-requisites\nSTAT 520 “Applied Multivariate Analysis” or STAT 615 “Regression”.\nTextbooks\nMain textbook\nThis book will be required reading and we will aim to cover most of the content.\n“An Introduction to Statistical Learning with Applications in R” by G. James, D. Witten, T. Hastie, and R. Tibshirani; Springer, 2013. ISBN 1461471370. The latest corrected printing is available on James’s page at https://statlearning.com/\nSupplementary books\nThese books are by no means necessary to buy or read to complete this course but serve as great stepping stones for deeper study. Some week’s readings will refer to these books for extra readings.\n“The Elements of Statistical Learning: Data Mining, Inference, and Prediction”, by T. Hastie, R. Tibshirani, and J. Friedman, 2nd Edition; Springer, 2009. ISBN 0387848576. Available on Hastie’s page at https://web.stanford.edu/~hastie/Papers/ESLII.pdf [more technical; contains advanced explanations and mathematical proofs].\n“Tidy Modeling with R” by Max Kuhn and Julia Silge. Available online at https://www.tmwr.org/.\nArticles, book chapters, and other materials\nThere will also occasionally be additional articles and videos to read and watch. When this happens, links to these other resources will be included on the reading page for that week.\nCourse Plan\nIntroduction, motivation, and examples. Understanding large and complex data sets. Statistical learning. First steps in R. [Chap. 1-2].\nReview of regression modeling and analysis; implementation in R. [Chap. 3].\nClassification problems and classification tools. Logistic regression and review of linear discriminant analysis. [Chap. 4]\nResampling methods; bootstrap. [Chap. 5 and lecture notes].\nHigh-dimensional data and shrinkage. Ridge regression. LASSO. Model selection methods and dimension reduction. Principal components. Partial least squares. [Chap. 6]\nNonlinear trends and splines. [Chap. 7; 7.4-7.5]\nRegression trees and decision trees [Chap. 8]\nIntroduction to support vector machines [Chap. 9]\nClustering methods [Chap. 10]\nAdditional topics and applications, if time permits.\nAssignments and grading\nAssignments (35%): During the semester I will assign, collect, and grade assignments. You may receive assistance from other students in the class and me, but your submissions must be composed of your own thoughts, coding, and words. A typical homework will include a few problems to do by hand, to see how things work, and a few realistic problems to do using R. Late submission is accepted at a cost of a 5% deduction for each day, with a maximum deduction of 50%.\nLabs (20%): 30-45 minute labs at the end of each class. Each lab covers the material of the lecture. You will have to submit the solutions of each lab on Blackboard the Sunday after each class.\nMidterm (15%): The midterm covers several chapters of the material and it is take home. You will have three days to complete the exam.\nProject (25%) (20% report 5% presentation): Each student will receive or choose a data set with data description, problem formulation, and instructions. Using sound statistical methods, you will do the necessary modeling and data analysis and write a report summarizing your results and answering specific questions of your project. A 10-minute presentation summarizing the report will be given to the class or submitted on Blackboard.\n90 – 100 % = A\n87 – 90 % = A-\n83 – 87 % = B+\n80 – 83 % = B\n77 – 80 % = B-\n73 – 77 = C+\n70 – 73 % = C\n60 – 70 % = C-\nPlease schedule a meeting with me if you would like to see or discuss your grade at any point during the semester.\nLearning objectives\nGraduate students (STAT 627)\nStudents will be able to:\nIdentify appropriate statistical learning methods for the given problem involving real data.\nUnderstand the underlying assumptions, verify them, and propose appropriate actions if some assumptions do not hold.\nIdentify other possible problems with messy data, such as multicollinearity, understand their consequences, and propose solutions.\nEvaluate the performance of the chosen regression and classification techniques and compare them.\nApply cross-validation techniques to find the optimal degree of flexibility - the best subset of predictors or the optimal tuning parameters.\nShow, analytically, or empirically, the optimal balance between precision within training data and prediction power.\nIllustrate results with appropriate plots and diagrams.\nUndergraduate students (STAT 427)\nStudents will be able to:\nIdentify appropriate statistical learning methods for the given problem involving real data.\nUnderstand the underlying assumptions, techniques available to verify them, and propose appropriate remedies.\nUse training and testing data to evaluate the performance of the chosen regression and classification techniques and compare them.\nUse available empirical tools to find the optimal balance between precision within training data and prediction power.\nIllustrate results with appropriate plots and diagrams.\nStudents will demonstrate competence in using different statistical learning methods involving large, messy, and multi-dimensional numerical and categorical data. Methods include linear, logistic, and polynomial regression with proper variable selection, linear and quadratic discriminant analysis, K-nearest neighbor classifier, bootstrap, ridge regression, lasso, principal components regression, partial least squares, splines, regression and classification trees, support vector machines, clustering, and related methods. In addition, graduate students (STAT 627) will demonstrate competency in the analytic justification of the chosen methods, tuning of the algorithms, and evaluating their prediction power.\nOnline help\nData science and statistical programming can be difficult. Computers are stupid and little errors in your code can cause hours of headache (even if you’ve been doing this stuff for years!).\nFortunately, there are tons of online resources to help you with this. Two of the most important are StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nIf you use Twitter, post R-related questions, and content with #rstats. The community there is exceptionally generous and helpful.\nSearching for help with R on Google can sometimes be tricky because the program name is, um, a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot,” but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”).\nAdditionally, we have a class chatroom at Slack where anyone in the class can ask questions and anyone can answer. I will monitor Slack regularly and will respond quickly. Ask questions about the readings, assignments, and project. You’ll likely have similar questions as your peers, and you’ll likely be able to answer other people’s questions too.\nSoftware\nWe will be using R and tidymodels in this class. While not required, it is highly recommended that you use an IDE for R, I recommend https://rstudio.com/products/rstudio/.\nLearning during a pandemic\nLife absolutely sucks right now. None of us is really okay. We’re all just pretending.\nYou most likely know people who have lost their jobs, have tested positive for COVID-19, have been hospitalized, or perhaps have even died. You all have increased (or possibly decreased) work responsibilities and increased family care responsibilities—you might be caring for extra people (young and/or old!) right now, and you are likely facing uncertain job prospects (or have been laid off!).\nI’m fully committed to making sure that you learn everything you were hoping to learn from this class! I will make whatever accommodations I can to help you finish your exercises, do well on your projects, and learn and understand the class material. Under ordinary conditions, I am flexible and lenient with grading and course expectations when students face difficult challenges. Under pandemic conditions, that flexibility and leniency are intensified.\nIf you tell me you’re having trouble, I will not judge you or think less of you. I hope you’ll extend me the same grace.\nYou never owe me personal information about your health (mental or physical). You are always welcome to talk to me about things that you’re going through, though. If I can’t help you, I usually know somebody who can.\nIf you need extra help, or if you need more time with something, or if you feel like you’re behind or not understanding everything, do not suffer in silence! Talk to me! I will work with you. I promise.\nLauren’s Promise\nI will listen and believe you if someone is threatening you.\nLauren McCluskey, a 21-year-old honors student-athlete, was murdered on October 22, 2018, by a man she briefly dated on the University of Utah campus. We must all take action to ensure that this never happens again.\nIf you are in immediate danger, call 911 or AU police (202 885-2527).\nIf you are experiencing sexual assault, domestic violence, or stalking, please report it to me and I will connect you to resources or find appropriate contact information for Counseling Center.\nSupport Services\nEmergency preparedness\nIn the event of an emergency, students should refer to the AU Web site http: //www.american.edu/emergency and the AU information line at (202) 885-1100 for general university-wide information. In case of a prolonged closure of the University, I send updates to you by email and will post all announcements on Blackboard.\nMathematics & Statistics Tutoring Lab (Don Myers Building)\nprovides tutoring in Intermediate Mathematics and Statistics. http://www.american.edu/cas/mathstat/tutoring.cfm\nAcademic Support and Access Center\noffers study skills workshops, individual instruction, tutor referrals, Supplemental Instruction, writing support, and technical and practical support and assistance with accommodations for students with physical, medical, or psychological disabilities. Writing support is also available in the Writing Center, Battelle-Tompkins 228.\nCenter for Diversity & Inclusion (X3651, MGC 201)\nis dedicated to enhancing LGBTQ, Multicultural, First Generation, and Women’s experiences on campus and to advance AU’s commitment to respecting & valuing diversity by serving as a resource and liaison to students, staff, and faculty on issues of equity through education, outreach, and advocacy.\nThe Office of Advocacy Services for Interpersonal and Sexual Violence (X7070)\nprovides free and confidential advocacy services for anyone in the campus community who is impacted by sexual violence (sexual assault, dating or domestic violence, and stalking).\nCounseling Center (x3500)\noffers counseling and consultations regarding personal concerns, self-help information, and connections to off-campus mental health resources. Academic Support and Access Center (x3360) offers study skills workshops, individual instruction, tutor referrals, Supplemental Instruction, writing support, and technical and practical support and assistance with accommodations for students with physical, medical, or psychological disabilities.\nReligious Holidays\nStudents may receive accommodation in the course for the observance of a religious and/or cultural holiday. The student should notify the professor as soon as possible should such a need exist. More information about accommodations for religious and/or cultural holidays can be found at www.american.edu/ocl/kay/request-for-religious-accommodation.cfm.\nAcademic Integrity Code\nPlease be sure that you are familiar with AU’s Academic Integrity Code, as I am required to report any cases of academic dishonesty to the dean of CAS. For your review: http://www.american.edu/academics/ integrity/.\n\n\n\n",
      "last_modified": "2021-01-25T18:02:00-08:00"
    }
  ],
  "collections": []
}
